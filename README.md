# ğŸ“¢ Bemba ASR Evaluation Pipeline

This project provides a complete pipeline for evaluating Automatic Speech Recognition (ASR) models on **Bemba-language** datasets. It focuses on calculating key transcription performance metrics â€” Word Error Rate (WER) and Character Error Rate (CER) â€” across multiple Hugging Face-hosted models.

---

## ğŸ¯ Key Features

- Loads and preprocesses Bemba test data (`KYAGABA/oromo_cleaned_dataset`)
- Supports multiple models via Hugging Face `pipeline()`
- Runs inference and logs predictions vs references
- Computes:
  - Word Error Rate (WER)
  - Character Error Rate (CER)
- Exports detailed CSV results for each model evaluated

---

## ğŸ—‚ï¸ Dataset

The test set is loaded from the Hugging Face Hub:

